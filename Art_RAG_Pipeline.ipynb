{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12b590b-ccfb-475b-9ab2-c152a66ea555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This requires two dependencies: langchain and langchain_aws\n",
    "# You also need datasets to use the wikiart-subject dataset\n",
    "# I've also chosen to use FAISS as a vector store & cache, which requires faiss-cpu and langchain-community\n",
    "# pip install langchain langchain_aws\n",
    "# pip install datasets\n",
    "# pip install faiss-cpu langchain-community\n",
    "\n",
    "# Available models:\n",
    "# amazon.titan-embed-text-v1\n",
    "# amazon.titan-embed-image-v1\n",
    "# anthropic.claude-3-5-sonnet-20240620-v1:0\n",
    "# cohere.embed-multilingual-v3\n",
    "# meta.llama3-70b-instruct-v1:0\n",
    "\n",
    "import boto3\n",
    "from langchain_aws.chat_models.bedrock import ChatBedrock\n",
    "from langchain_aws.embeddings.bedrock import BedrockEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "from datasets import load_dataset\n",
    "import faiss\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset:\n",
    "# https://huggingface.co/datasets/jlbaker361/wikiart-subjects\n",
    "full_dataset = load_dataset(\"jlbaker361/wikiart-subjects\")\n",
    "\n",
    "# For development, let's use a smaller subset of the full dataset, since it's quite large (815MB)\n",
    "# Let's take a 5% random sample from the \"train\" split.\n",
    "#small_dataset = full_dataset[\"train\"].train_test_split(test_size=0.05)[\"test\"]\n",
    "\n",
    "# Optionally, if we set also a seed, we'll get the same subset each time; the consistency can be handy for testing & debugging.\n",
    "small_dataset = full_dataset[\"train\"].train_test_split(test_size=0.05, seed=42)[\"test\"]\n",
    "\n",
    "# Just to see that the data is there, convert it to DataFrame and display the first few rows\n",
    "small_dataset_df = small_dataset.to_pandas()\n",
    "print(small_dataset_df.head())  # Display the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d302793-f5f4-4f13-9d67-e0a43525179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a session with AWS via the Boto3 Python SDK.\n",
    "session = boto3.Session(\n",
    "  aws_access_key_id='[AWS_ACCESS_KEY_ID]',\n",
    "  aws_secret_access_key='[AWS_SECRET_ACCESS_KEY]',\n",
    "  region_name='us-east-1'\n",
    ")\n",
    "\n",
    "# Connect to Bedrock services so we can access models for embeddings & chat.\n",
    "client = session.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f4a9dc-2cb8-463e-b549-93f558f6df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to create embeddings for our dataset and store them in a vector database.\n",
    "# I have chosen FAISS as a vector db because it runs locally instead of in the cloud,\n",
    "# so I don't have to sign up for an account, a subscription, etc.\n",
    "# \n",
    "# For added efficiency, I'm also storing the FAISS db in a local index file, to act as a cache\n",
    "# so that I don't recreate embeds over and over if I restart Jupyter, preventing wasteful API calls to AWS.\n",
    "\n",
    "text_embed_model = 'amazon.titan-embed-text-v1'\n",
    "image_embed_model = 'amazon.titan-embed-image-v1'\n",
    "INDEX_PATH = \"faiss_index_file\"  # File path for saving/loading FAISS index\n",
    "dimension = 1024  # Default vector dimensions for Amazon's titan embed models; 384 and 256 also supported\n",
    "docstore = InMemoryDocstore({})\n",
    "index_to_docstore_id = {}  # Empty mapping to start\n",
    "# Read more about the models here:\n",
    "# https://docs.aws.amazon.com/bedrock/latest/userguide/titan-embedding-models.html\n",
    "# https://docs.aws.amazon.com/bedrock/latest/userguide/titan-multiemb-models.html\n",
    "\n",
    "# Helper function: generates a text embedding\n",
    "def generate_text_embedding(text):\n",
    "    response = client.invoke_model(\n",
    "        modelId=text_embed_model,\n",
    "        body={\"text\": text}\n",
    "    )\n",
    "    embedding = response['body']['embedding']\n",
    "    return embedding\n",
    "\n",
    "# Helper function: generates an image embedding\n",
    "def generate_image_embedding(image_data):\n",
    "    response = client.invoke_model(\n",
    "        modelId=image_embed_model,\n",
    "        body={\"image\": image_data}\n",
    "    )\n",
    "    embedding = response['body']['embedding']\n",
    "    return embedding\n",
    "\n",
    "# Step 1: Load or Initialize FAISS Index\n",
    "if os.path.exists(INDEX_PATH):\n",
    "    print(\"Loading existing FAISS index...\")\n",
    "    index = faiss.read_index(INDEX_PATH)\n",
    "else:\n",
    "    print(\"No FAISS index found. Initializing a new one...\")\n",
    "    index = faiss.IndexFlatL2(dimension)  # L2 distance index\n",
    "\n",
    "# Step 2: Add rows to FAISS if they are not already there\n",
    "def add_to_faiss_if_missing(row_data):\n",
    "    text, style, image = row_data[\"text\"], row_data[\"style\"], row_data[\"image\"]\n",
    "\n",
    "    # Combine text and style for a single embedding; embed image separately\n",
    "    combined_text = f\"{text} - Style: {style}\"\n",
    "    \n",
    "    # Check if already in FAISS\n",
    "    unique_id = get_unique_id(text)\n",
    "    if unique_id not in embedding_map:\n",
    "        # Embed each component\n",
    "        text_embedding = generate_text_embedding(text)\n",
    "        style_embedding = generate_text_embedding(style)\n",
    "        image_embedding = generate_image_embedding(image)\n",
    "    \n",
    "        # Add to FAISS\n",
    "        vector_db.add_texts([combined_text], embeddings=[text_embedding + style_embedding + image_embedding])\n",
    "        docstore[doc_id] = unique_id\n",
    "\n",
    "# Step 3: Process dataset and add rows to FAISS as necessary\n",
    "vector_db = FAISS(\n",
    "    index=index,\n",
    "    embedding_function=add_to_faiss_if_missing,\n",
    "    docstore=docstore,\n",
    "    index_to_docstore_id=index_to_docstore_id\n",
    ")\n",
    "\n",
    "for row in small_dataset:  # Assuming `dataset` is iterable with each row as a dictionary of `text`, `style`, `image`\n",
    "    add_to_faiss_if_missing(row)\n",
    "\n",
    "# Step 4: Save the FAISS index\n",
    "faiss.write_index(vector_db.index, INDEX_PATH)\n",
    "# TODO: can the docstore also be saved to disk like this?\n",
    "print(\"FAISS index saved to disk.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121ae131-2f05-4e96-8377-1d97b800b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I've heard Claude is nice in conversation, so let's try it!\n",
    "claude_model = ChatBedrock(model_id='anthropic.claude-3-5-sonnet-20240620-v1:0')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
